{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "\n",
    "# MachineLearning\n",
    "<hr style=\"border:2px solid gray\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0. Import packages and Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "data_name = 'image_data.npy'\n",
    "category_file_name = 'Categories.txt'\n",
    "model_dir = './model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(7947, 64, 64, 3) (7947, 100)\n(2650, 64, 64, 3) (2650, 100)\n"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = np.load(data_name, allow_pickle=True)\n",
    "\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "category_file = codecs.open(category_file_name, 'r', 'utf-8')\n",
    "categories = list(map(str.strip, category_file.readlines()))\n",
    "classes = len(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\", input_shape=X_train.shape[1:], activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Conv2D(64, (3,3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "    \n",
    "model_path = model_dir + '/model.model'\n",
    "checkpoint = ModelCheckpoint(filepath=model_path , monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: &quot;sequential_1&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            (None, 64, 64, 32)        896       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 32, 32, 32)        0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 32, 32, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 16, 16, 64)        0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 16384)             0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               4194560   \n_________________________________________________________________\ndropout_5 (Dropout)          (None, 256)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 100)               25700     \n=================================================================\nTotal params: 4,239,652\nTrainable params: 4,239,652\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 4.2481 - accuracy: 0.0478\nEpoch 00001: val_loss improved from inf to 3.98583, saving model to ./model\\model.model\nWARNING:tensorflow:From c:\\ML\\plant-recognizer\\ML\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\nWARNING:tensorflow:From c:\\ML\\plant-recognizer\\ML\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis property should not be used in TensorFlow 2.0, as updates are applied automatically.\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 20s 79ms/step - loss: 4.2473 - accuracy: 0.0479 - val_loss: 3.9858 - val_accuracy: 0.1049\nEpoch 2/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 3.8229 - accuracy: 0.1066\nEpoch 00002: val_loss improved from 3.98583 to 3.69006, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 78ms/step - loss: 3.8230 - accuracy: 0.1066 - val_loss: 3.6901 - val_accuracy: 0.1645\nEpoch 3/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 3.5754 - accuracy: 0.1494\nEpoch 00003: val_loss improved from 3.69006 to 3.47449, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 75ms/step - loss: 3.5757 - accuracy: 0.1495 - val_loss: 3.4745 - val_accuracy: 0.1977\nEpoch 4/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 3.4015 - accuracy: 0.1744\nEpoch 00004: val_loss improved from 3.47449 to 3.29921, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 75ms/step - loss: 3.4019 - accuracy: 0.1743 - val_loss: 3.2992 - val_accuracy: 0.2283\nEpoch 5/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 3.2698 - accuracy: 0.1990\nEpoch 00005: val_loss improved from 3.29921 to 3.19507, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 76ms/step - loss: 3.2700 - accuracy: 0.1987 - val_loss: 3.1951 - val_accuracy: 0.2275\nEpoch 6/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 3.1216 - accuracy: 0.2225\nEpoch 00006: val_loss improved from 3.19507 to 3.12856, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 76ms/step - loss: 3.1218 - accuracy: 0.2223 - val_loss: 3.1286 - val_accuracy: 0.2487\nEpoch 7/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.9851 - accuracy: 0.2436\nEpoch 00007: val_loss improved from 3.12856 to 3.10183, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 75ms/step - loss: 2.9844 - accuracy: 0.2436 - val_loss: 3.1018 - val_accuracy: 0.2445\nEpoch 8/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.8445 - accuracy: 0.2670\nEpoch 00008: val_loss improved from 3.10183 to 3.05305, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 76ms/step - loss: 2.8434 - accuracy: 0.2669 - val_loss: 3.0530 - val_accuracy: 0.2562\nEpoch 9/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.7039 - accuracy: 0.2926\nEpoch 00009: val_loss improved from 3.05305 to 3.05224, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 19s 76ms/step - loss: 2.7043 - accuracy: 0.2923 - val_loss: 3.0522 - val_accuracy: 0.2525\nEpoch 10/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.5712 - accuracy: 0.3177\nEpoch 00010: val_loss improved from 3.05224 to 3.02942, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 20s 81ms/step - loss: 2.5706 - accuracy: 0.3179 - val_loss: 3.0294 - val_accuracy: 0.2577\nEpoch 11/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.4491 - accuracy: 0.3419\nEpoch 00011: val_loss did not improve from 3.02942\n249/249 [==============================] - 19s 75ms/step - loss: 2.4492 - accuracy: 0.3419 - val_loss: 3.0436 - val_accuracy: 0.2464\nEpoch 12/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.3441 - accuracy: 0.3598\nEpoch 00012: val_loss improved from 3.02942 to 3.01808, saving model to ./model\\model.model\nINFO:tensorflow:Assets written to: ./model\\model.model\\assets\n249/249 [==============================] - 20s 82ms/step - loss: 2.3432 - accuracy: 0.3600 - val_loss: 3.0181 - val_accuracy: 0.2558\nEpoch 13/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.2011 - accuracy: 0.3882\nEpoch 00013: val_loss did not improve from 3.01808\n249/249 [==============================] - 18s 72ms/step - loss: 2.2011 - accuracy: 0.3883 - val_loss: 3.0350 - val_accuracy: 0.2694\nEpoch 14/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 2.0789 - accuracy: 0.4194\nEpoch 00014: val_loss did not improve from 3.01808\n249/249 [==============================] - 18s 72ms/step - loss: 2.0796 - accuracy: 0.4190 - val_loss: 3.1188 - val_accuracy: 0.2562\nEpoch 15/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 1.9916 - accuracy: 0.4389\nEpoch 00015: val_loss did not improve from 3.01808\n249/249 [==============================] - 18s 72ms/step - loss: 1.9919 - accuracy: 0.4389 - val_loss: 3.1082 - val_accuracy: 0.2691\nEpoch 16/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 1.8750 - accuracy: 0.4618\nEpoch 00016: val_loss did not improve from 3.01808\n249/249 [==============================] - 18s 72ms/step - loss: 1.8754 - accuracy: 0.4617 - val_loss: 3.1885 - val_accuracy: 0.2672\nEpoch 17/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 1.7952 - accuracy: 0.4793\nEpoch 00017: val_loss did not improve from 3.01808\n249/249 [==============================] - 18s 72ms/step - loss: 1.7961 - accuracy: 0.4792 - val_loss: 3.1756 - val_accuracy: 0.2683\nEpoch 18/50\n248/249 [============================&gt;.] - ETA: 0s - loss: 1.7252 - accuracy: 0.4903\nEpoch 00018: val_loss did not improve from 3.01808\n249/249 [==============================] - 18s 72ms/step - loss: 1.7243 - accuracy: 0.4905 - val_loss: 3.2489 - val_accuracy: 0.2657\n83/83 [==============================] - 1s 12ms/step - loss: 3.2489 - accuracy: 0.2657\n정확도 : 0.2657\n"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test), callbacks=[checkpoint, early_stopping])\n",
    "print(\"정확도 : %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "source": [
    "# Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&#39;tensorflow&#39;"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "K.backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.6 64-bit ('ML': venv)",
   "display_name": "Python 3.8.6 64-bit ('ML': venv)",
   "metadata": {
    "interpreter": {
     "hash": "0d637d56708b5b1bb758d06434c40cfbe4ca31034e9d00bfb05663f8a5792e9e"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}